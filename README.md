# CResPIE-ViT: A Compact Vision Transformer-based Framework for COVID-19 Lesion Segmentation and Severity Analysis

## Article Under Review with IEEE TRANSACTIONS ON RADIATION AND PLASMA MEDICAL SCIENCES (TRPMS) (IF=3.5).
## Original code will be available post peer-review decision.

The ubiquitous impact of the highly contagious
Coronavirus Disease (COVID-19) extended beyond human mortality
to cripple the global medical infrastructure. Its symptoms
are almost identical to viral pneumonia, but the consequences
are fatal. As such, it is imperative to deploy robust artificially
intelligent computer vision paradigms for the early detection
of COVID-19 and thus cure patients from adverse effects. To
capture both low-level contexts and global-level semantics, we
have exploited the principles of vision transformer along with
depthwise separable convolutions. This article proposes a hybrid
deep learning framework called CResPIE-ViT, which has two
versions, CResPIE-ViTv1 and CResPIE-ViTv2 (or CResPIESegViT).
These neural networks constitute a novel and extremely
lightweight Compact Vision Transformer (CViT) integrated with
residual blocks of the Principle Information Extractor (PIE) module
for COVID-19 severity prediction and lesion segmentation
using CT scans, respectively. The novel PIE attention module
is introduced to extract important features from the channel
and spatial levels of abstraction. Residual connections ensure the
preservation of high-level gradients and facilitate efficient and
fast optimization. The proposed deep learning frameworks have
outperformed several state-of-the-art methods on the MosMed
and Seg20Cases datasets.


